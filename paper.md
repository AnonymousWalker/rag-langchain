# An Evaluation of Retrieval-augmented generation on Scripture Assistant

Introduction
LLMs demonstrated remarkable capabilities in understanding and generating human-like text, thereby transforming various sectors including healthcare, finance, and customer service. Despite their impressive performance, LLMs face significant limitations, particularly in terms of generating factually accurate and contextually relevant information consistently.

This white paper focuses on evaluating the performance of RAG, RAG-Fusion in particular, compared to traditional LLMs. Through a detailed analysis, we aim to examine how RAG enhances the capabilities of LLMs, providing empirical evidence and practical insights into its effectiveness.


The chat API we created was based on RAG-Fusion technique. 
<diagram>

The three major components are:

### 1. Query generation


### 2. Context Retrieval


### 3. Context Ranking


## Prompt engineering - Guidance conditions

### No Guidance

### Low Guidance

### High Guidance


## Conclusion
By providing a thorough assessment of RAG's performance, this white paper seeks to contribute to the ongoing discourse on enhancing AI-driven text generation. It aims to equip stakeholders with the knowledge and insights necessary to make informed decisions about adopting and implementing RAG in their AI systems.
